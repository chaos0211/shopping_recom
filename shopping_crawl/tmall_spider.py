import time
import os
import json
import requests
import mysql.connector
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import TimeoutException, NoSuchElementException
from sqlalchemy import create_engine, Column, Integer, String, Float, DateTime, Text
from sqlalchemy.orm import declarative_base
from sqlalchemy.orm import sessionmaker
from datetime import datetime
import urllib.parse
from PIL import Image
import io

Base = declarative_base()


class Product(Base):
    __tablename__ = 'tmall_products'

    id = Column(Integer, primary_key=True, autoincrement=True)
    item_id = Column(String(50), unique=True, nullable=False)  # æ–°å¢å•†å“idå­—æ®µ
    name = Column(String(500), nullable=False)
    price = Column(Float)
    image_url = Column(Text)
    local_image_path = Column(String(500))
    shop_name = Column(String(200))
    shop_rating = Column(String(50))
    category = Column(String(100))
    crawled_at = Column(DateTime, default=datetime.now)


class TmallCrawler:
    def __init__(self, db_config, image_dir="./images"):
        """
        åˆå§‹åŒ–çˆ¬è™«

        Args:
            db_config: æ•°æ®åº“é…ç½®å­—å…¸
            image_dir: å›¾ç‰‡ä¿å­˜ç›®å½•
        """
        self.db_config = db_config
        self.image_dir = image_dir
        self.driver = None
        self.session = None
        self.cookies_file = "tmall_cookies.json"

        # åˆ›å»ºå›¾ç‰‡ç›®å½•
        os.makedirs(self.image_dir, exist_ok=True)

        # åˆå§‹åŒ–æ•°æ®åº“
        self.init_database()

    def init_database(self):
        """åˆå§‹åŒ–æ•°æ®åº“è¿æ¥å’Œè¡¨ç»“æ„"""
        try:
            # åˆ›å»ºæ•°æ®åº“å¼•æ“
            engine_url = f"mysql+pymysql://{self.db_config['user']}:{self.db_config['password']}@{self.db_config['host']}:{self.db_config['port']}/{self.db_config['database']}"
            self.engine = create_engine(engine_url, echo=False)

            # åˆ›å»ºè¡¨
            Base.metadata.create_all(self.engine)

            # åˆ›å»ºä¼šè¯
            Session = sessionmaker(bind=self.engine)
            self.session = Session()

            print("æ•°æ®åº“è¿æ¥æˆåŠŸï¼")
        except Exception as e:
            print(f"æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            raise

    def init_driver(self):
        """åˆå§‹åŒ–Chromeé©±åŠ¨"""
        try:
            chrome_options = Options()
            # è®¾ç½®User-Agent
            chrome_options.add_argument(
                "--user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
            # ç¦ç”¨å›¾ç‰‡åŠ è½½ä»¥æé«˜é€Ÿåº¦ï¼ˆå¯é€‰ï¼‰
            # chrome_options.add_argument("--blink-settings=imagesEnabled=false")
            # ç¦ç”¨é€šçŸ¥
            chrome_options.add_argument("--disable-notifications")
            # è®¾ç½®çª—å£å¤§å°
            chrome_options.add_argument("--window-size=1920,1080")
            # ç¦ç”¨æ— å¤´æ¨¡å¼ï¼Œç¡®ä¿æ‰«ç ç™»å½•äºŒç»´ç å¯ä»¥æ­£å¸¸æ˜¾ç¤º
            # chrome_options.add_argument("--headless")  # æ— å¤´ï¼Œæ³¨é‡Šæ‰ï¼Œé¿å…å¼‚æ­¥å†…å®¹æ— æ³•æ¸²æŸ“

            # åœ¨macOSä¸Šï¼Œé€šå¸¸Chromeé©±åŠ¨åœ¨PATHä¸­
            from selenium.webdriver.chrome.service import Service

            chrome_driver_path = "shopping_crawl/chromedriver"  # â† è¯·ä¿®æ”¹ä¸ºä½ è‡ªå·±çš„chromedriverè·¯å¾„
            service = Service(executable_path=chrome_driver_path)
            self.driver = webdriver.Chrome(service=service, options=chrome_options)
            self.driver.implicitly_wait(3)

            print("Chromeé©±åŠ¨åˆå§‹åŒ–æˆåŠŸï¼")
            return True
        except Exception as e:
            print(f"Chromeé©±åŠ¨åˆå§‹åŒ–å¤±è´¥: {e}")
            print("è¯·ç¡®ä¿å·²å®‰è£…Chromeæµè§ˆå™¨å’ŒChromeDriver")
            return False

    def save_cookies(self):
        """ä¿å­˜cookiesåˆ°æ–‡ä»¶"""
        try:
            cookies = self.driver.get_cookies()
            for cookie in cookies:
                if 'domain' not in cookie or 'taobao.com' not in cookie['domain']:
                    cookie['domain'] = '.taobao.com'

            with open(self.cookies_file, 'w', encoding='utf-8') as f:
                json.dump(cookies, f, ensure_ascii=False, indent=2)
            print("Cookieså·²ç¨³å®šä¿å­˜")
        except Exception as e:
            print(f"ä¿å­˜cookieså¤±è´¥: {e}")

    def load_cookies(self):
        try:
            with open(self.cookies_file, 'r', encoding='utf-8') as f:
                cookies = json.load(f)

            self.driver.get("https://www.taobao.com")
            time.sleep(3)

            self.driver.delete_all_cookies()
            for cookie in cookies:
                if 'domain' in cookie and ('taobao.com' not in cookie['domain']):
                    cookie['domain'] = '.taobao.com'
                self.driver.add_cookie(cookie)

            self.driver.refresh()
            time.sleep(3)
            print("Cookieså·²åŠ è½½ï¼Œå¹¶é‡æ–°åˆ·æ–°é¡µé¢")
            return True
        except Exception as e:
            print(f"åŠ è½½cookieså¤±è´¥: {e}")
            return False

    def login_with_qr(self):
        """ä½¿ç”¨äºŒç»´ç ç™»å½•"""
        try:
            print("æ­£åœ¨æ‰“å¼€å¤©çŒ«ç™»å½•é¡µé¢...")
            self.driver.get("https://login.tmall.com/")
            time.sleep(3)

            # æŸ¥æ‰¾äºŒç»´ç å…ƒç´ 
            try:
                qr_element = WebDriverWait(self.driver, 10).until(
                    EC.presence_of_element_located((By.CSS_SELECTOR, "#J_QRCodeLogin img"))
                )
                print("äºŒç»´ç å·²æ˜¾ç¤ºï¼Œè¯·ä½¿ç”¨æ‰‹æœºæ·˜å®æ‰«æäºŒç»´ç ç™»å½•")

                # ç­‰å¾…ç™»å½•æˆåŠŸï¼ˆæ£€æŸ¥æ˜¯å¦è·³è½¬åˆ°é¦–é¡µæˆ–å‡ºç°ç”¨æˆ·ä¿¡æ¯ï¼‰
                login_success = False
                max_wait_time = 120  # æœ€å¤šç­‰å¾…2åˆ†é’Ÿ
                start_time = time.time()

                while time.time() - start_time < max_wait_time:
                    current_url = self.driver.current_url
                    if "login" not in current_url.lower() or self.check_login_status():
                        login_success = True
                        break
                    time.sleep(1)

                if login_success:
                    print("ç™»å½•æˆåŠŸï¼")
                    self.save_cookies()
                    return True
                else:
                    print("ç™»å½•è¶…æ—¶ï¼Œè¯·é‡è¯•")
                    return False

            except TimeoutException:
                print("âš ï¸ æœªæ‰¾åˆ°äºŒç»´ç ï¼Œå¯èƒ½é¡µé¢ç»“æ„å·²å˜åŒ–")
                print("è¯·æ‰‹åŠ¨ç™»å½•å¤©çŒ«è´¦å·ï¼Œç™»å½•å®Œæˆåè¾“å…¥ '1' ç¡®è®¤ç»§ç»­...")
                while True:
                    confirm = input("ğŸ‘‰ ç™»å½•æˆåŠŸåè¯·è¾“å…¥ 1 ç¡®è®¤ç»§ç»­ï¼š")
                    if confirm.strip() == "1":
                        break
                if self.check_login_status():
                    print("âœ… ç™»å½•æˆåŠŸ")
                    self.save_cookies()
                    return True
                else:
                    print("âŒ ç™»å½•å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ˜¯å¦æ­£ç¡®ç™»å½•")
                    return False

        except Exception as e:
            print(f"ç™»å½•è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
            return False

    def check_login_status(self):
        """æ£€æŸ¥ç™»å½•çŠ¶æ€"""
        try:
            # æ£€æŸ¥ URL æ˜¯å¦ä¸å†æ˜¯ç™»å½•é¡µ
            current_url = self.driver.current_url
            if "login" not in current_url.lower():
                return True

            # æˆ–è€…æ£€æŸ¥æ˜¯å¦å‡ºç°ç”¨æˆ·å¤´åƒæˆ–æ˜µç§°åŒºåŸŸ
            user_selectors = [
                ".site-nav-user", ".user-avatar", "#J_SiteNavLogin .nickname",
                ".site-nav-login-info", "#J_SiteNavLogin .s-user-name"
            ]

            for selector in user_selectors:
                try:
                    elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                    if elements and elements[0].is_displayed():
                        return True
                except:
                    continue

            return False
        except Exception as e:
            print(f"ç™»å½•çŠ¶æ€åˆ¤æ–­å‡ºé”™: {e}")
            return False

    def search_products(self, keyword, max_pages=30):
        """æœç´¢å•†å“"""
        try:
            print(f"å¼€å§‹æœç´¢å•†å“: {keyword}")

            search_url = f"https://s.taobao.com/search?tab=mall&q={urllib.parse.quote(keyword)}"
            self.driver.get(search_url)
            time.sleep(5)  # å¢åŠ åˆå§‹ç­‰å¾…ï¼Œç¡®ä¿é¡µé¢åŠ è½½å®Œæ•´

            # é¡µé¢åŠ è½½åï¼Œå°è¯•å‘ä¸‹æ»šåŠ¨è§¦å‘æ‡’åŠ è½½
            for _ in range(5):
                self.driver.execute_script("window.scrollBy(0, 1000);")
                time.sleep(1)

            products = []

            for page in range(1, max_pages + 1):
                print(f"[è°ƒè¯•] å½“å‰çˆ¬å–é¡µç : {page}")
                print(f"æ­£åœ¨çˆ¬å–ç¬¬ {page} é¡µ...")
                page_start_time = time.time()

                # æ˜ç¡®ä½¿ç”¨XPathç­‰å¾…å•†å“åˆ—è¡¨åŠ è½½
                try:
                    WebDriverWait(self.driver, 15).until(
                        EC.presence_of_element_located((By.XPATH, '//*[@id="content_items_wrapper"]/div'))
                    )
                except TimeoutException:
                    print("å•†å“åˆ—è¡¨åŠ è½½è¶…æ—¶")
                    self.driver.save_screenshot("debug_page_timeout.png")
                    break

                page_products = self.parse_products_page(keyword)
                if page_products:
                    self.save_to_database(page_products)  # æ¯é¡µä¿å­˜ä¸€æ¬¡
                products.extend(page_products)

                self.driver.save_screenshot(f"./debug_img/page_{page}.png")

                # ç¿»é¡µæ“ä½œ
                if page < max_pages:
                    if not self.go_to_next_page():
                        print("æ²¡æœ‰æ›´å¤šé¡µé¢äº†")
                        break

                page_end_time = time.time()
                print(f"[è°ƒè¯•] ç¬¬ {page} é¡µçˆ¬å–è€—æ—¶: {page_end_time - page_start_time:.2f} ç§’")
                time.sleep(2)

            print(f"æ€»å…±çˆ¬å–åˆ° {len(products)} ä¸ªå•†å“")
            return products

        except Exception as e:
            print(f"æœç´¢å•†å“æ—¶å‡ºé”™: {e}")
            return []

    def parse_products_page(self, category):
        """è§£æå½“å‰é¡µé¢çš„å•†å“ä¿¡æ¯"""
        products = []

        try:
            # è°ƒè¯•ä¿¡æ¯
            print(f"[è°ƒè¯•] å½“å‰é¡µé¢åœ°å€: {self.driver.current_url}")
            # print(f"[è°ƒè¯•] é¡µé¢HTMLé¢„è§ˆï¼ˆå‰500å­—ç¬¦ï¼‰: {self.driver.page_source[:500]}")

            # ç›´æ¥ä½¿ç”¨XPathæŸ¥æ‰¾å•†å“å…ƒç´ 
            product_elements = self.driver.find_elements(By.XPATH, '//*[@id="content_items_wrapper"]/div')
            print(f"[è°ƒè¯•] æ‰¾åˆ°å•†å“æ•°é‡: {len(product_elements)}")

            if not product_elements:
                print("[è°ƒè¯•] æœªæ‰¾åˆ°å•†å“å®¹å™¨ï¼Œä¿å­˜å½“å‰é¡µé¢æˆªå›¾ä¸º debug_page.png")
                self.driver.save_screenshot("debug_page.png")
                return products

            for element in product_elements:
                try:
                    product_info = self.extract_product_info(element, category)
                    if product_info:
                        products.append(product_info)
                except Exception as e:
                    print(f"è§£æå•ä¸ªå•†å“æ—¶å‡ºé”™: {e}")
                    continue

        except Exception as e:
            print(f"è§£æé¡µé¢æ—¶å‡ºé”™: {e}")

        return products

    def extract_product_info(self, element, category):
        # æ–°å¢item_idå­—æ®µ
        product_info = {
            'item_id': '',  # æ–°å¢
            'category': category,
            'name': '',
            'price': '',
            'image_url': '',
            'shop_name': '',
            'shop_rating': ''
        }

        try:
            # è·å–item_id
            a_elements = element.find_elements(By.XPATH, './/a[contains(@id, "item_id_")]')
            if not a_elements:
                print("å•†å“idæœªæ‰¾åˆ°ï¼Œç›´æ¥è·³è¿‡")
                return None
            item_id = a_elements[0].get_attribute("id")
            if not item_id:
                print("æœªæ‰¾åˆ°å•†å“item_idï¼Œè·³è¿‡è¯¥å•†å“")
                return None
            product_info['item_id'] = item_id
            # æ–°å¢è·³è¿‡é€»è¾‘ï¼šè‹¥æ•°æ®åº“ä¸­å·²å­˜åœ¨è¯¥item_idä¸”image_urlå­—æ®µä¸ä¸ºç©ºï¼Œåˆ™è·³è¿‡è¯¥å•†å“
            existing_product = self.session.query(Product).filter_by(item_id=item_id).first()
            if existing_product and existing_product.image_url:
                print(f"è·³è¿‡å•†å“ {item_id}ï¼Œå› å·²å­˜åœ¨ä¸”image_urlä¸ä¸ºç©º")
                return None
            base_xpath = f'//*[@id="{item_id}"]'

            # å•†å“å›¾ç‰‡URL
            img_xpath_1 = base_xpath + '/div/div[1]/div[2]/img[1]'
            img_xpath_2 = base_xpath + '/div/div[1]/div[1]/img[1]'
            try:
                try:
                    img_element = self.driver.find_element(By.XPATH, img_xpath_1)
                except:
                    img_element = self.driver.find_element(By.XPATH, img_xpath_2)
                img_url = img_element.get_attribute('src') or img_element.get_attribute('data-ks-lazyload')
                if img_url and img_url.startswith("//"):
                    img_url = "https:" + img_url
                product_info['image_url'] = img_url
            except Exception as e:
                print(f"å•†å“å›¾ç‰‡URLæå–å¤±è´¥, äº§å“ç±»åˆ«å’Œè·¯å¾„ä¸º", category, img_xpath_1, img_xpath_2)

            # å•†å“åç§°
            name_xpath = base_xpath + '/div/div[1]/div[3]/div/span'
            try:
                name_element = self.driver.find_element(By.XPATH, name_xpath)
                product_info['name'] = name_element.text.strip()
            except Exception as e:
                print(f"å•†å“åç§°æå–å¤±è´¥:", name_xpath)

            # å•†å“ä»·æ ¼
            price_xpath = base_xpath + '//div[contains(@class, "priceInt")]'
            try:
                price_element = self.driver.find_element(By.XPATH, price_xpath)
                product_info['price'] = price_element.text.strip()
            except Exception as e:
                print(f"å•†å“ä»·æ ¼æå–å¤±è´¥:", price_xpath)

            # åº—é“ºåç§°
            shop_xpath = base_xpath + '//span[contains(@class, "shopNameText")]'
            try:
                shop_element = self.driver.find_element(By.XPATH, shop_xpath)
                product_info['shop_name'] = shop_element.text.strip()
            except Exception as e:
                print(f"åº—é“ºåç§°æå–å¤±è´¥:", shop_xpath)

            # æš‚æ— è¯„åˆ†å­—æ®µï¼Œä¿ç•™é»˜è®¤
            product_info['shop_rating'] = ''

            # éªŒè¯å•†å“åç§°æ˜¯å¦æˆåŠŸè·å–
            if product_info['name']:
                return product_info
            else:
                print("å•†å“åç§°ä¸ºç©ºï¼Œè·³è¿‡è¯¥å•†å“")
                return None

        except Exception as e:
            print(f"è§£æå•†å“ä¿¡æ¯æ—¶å‘ç”Ÿå¼‚å¸¸:")
            return None

    def download_image(self, image_url, product_name, existing_product=None):
        """ä¸‹è½½å•†å“å›¾ç‰‡ï¼Œä½¿ç”¨SHA1å¤„ç†æ–‡ä»¶å"""
        import hashlib
        try:
            if existing_product and existing_product.image_url:
                return existing_product.local_image_path
            if not image_url:
                return None

            # ä¸‹è½½å›¾ç‰‡
            headers = {'User-Agent': 'Mozilla/5.0'}
            response = requests.get(image_url, headers=headers, timeout=10)

            if response.status_code == 200:
                # ä½¿ç”¨SHA1å¤„ç†æ–‡ä»¶å
                sha1_hash = hashlib.sha1(response.content).hexdigest()
                filename = f"{sha1_hash}.jpg"
                filepath = os.path.join(self.image_dir, filename)

                with open(filepath, 'wb') as f:
                    f.write(response.content)

                print(f"å›¾ç‰‡å·²ä¸‹è½½: {filename}")
                return filepath
            else:
                print(f"ä¸‹è½½å›¾ç‰‡å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}")
                return None

        except Exception as e:
            print(f"ä¸‹è½½å›¾ç‰‡æ—¶å‡ºé”™: {e}")
            return None

    def save_to_database(self, products):
        """å°†å•†å“ä¿¡æ¯ä¿å­˜åˆ°æ•°æ®åº“ï¼Œå»é‡å¹¶æ›´æ–°"""
        from sqlalchemy.exc import IntegrityError
        import hashlib
        try:
            saved_count = 0
            for product in products:
                if not product:
                    continue

                # æ£€æŸ¥æ•°æ®åº“æ˜¯å¦å­˜åœ¨æ­¤item_id
                existing_product = self.session.query(Product).filter_by(item_id=product['item_id']).first()

                # ä¸‹è½½å›¾ç‰‡
                local_image_path = None
                if product.get('image_url'):
                    local_image_path = self.download_image(product['image_url'], product['name'], existing_product)

                if existing_product:
                    # å­˜åœ¨åˆ™æ›´æ–°
                    existing_product.name = product['name'][:500]
                    existing_product.price = product.get('price', '')[:100]
                    existing_product.image_url = product.get('image_url', '')
                    existing_product.local_image_path = local_image_path or existing_product.local_image_path
                    existing_product.shop_name = product.get('shop_name', '')[:200]
                    existing_product.shop_rating = product.get('shop_rating', '')[:50]
                    existing_product.category = product.get('category', '')[:100]
                    existing_product.crawled_at = datetime.now()
                else:
                    # æ–°å¢æ•°æ®
                    db_product = Product(
                        item_id=product['item_id'],
                        name=product['name'][:500],
                        price=product.get('price', '')[:100],
                        image_url=product.get('image_url', ''),
                        local_image_path=local_image_path or '',
                        shop_name=product.get('shop_name', '')[:200],
                        shop_rating=product.get('shop_rating', '')[:50],
                        category=product.get('category', '')[:100]
                    )
                    self.session.add(db_product)

                saved_count += 1

            self.session.commit()
            print(f"æˆåŠŸå¤„ç† {saved_count} ä¸ªå•†å“åˆ°æ•°æ®åº“ï¼ˆå«æ›´æ–°å’Œæ–°å¢ï¼‰")

        except IntegrityError as e:
            self.session.rollback()
            print(f"æ•°æ®åº“å®Œæ•´æ€§é”™è¯¯: {e}")
        except Exception as e:
            self.session.rollback()
            print(f"ä¿å­˜åˆ°æ•°æ®åº“æ—¶å‡ºé”™: {e}")

    def go_to_next_page(self):
        """ç¿»åˆ°ä¸‹ä¸€é¡µ"""
        try:
            # ç²¾ç¡®å®šä½â€œä¸‹ä¸€é¡µâ€æŒ‰é’®
            next_button = self.driver.find_element(By.CSS_SELECTOR, 'button.next-pagination-item.next-next')

            if next_button and next_button.is_enabled():
                self.driver.execute_script("arguments[0].click();", next_button)
                time.sleep(5)  # ç­‰å¾…é¡µé¢åŠ è½½
                return True
            else:
                print("å·²åˆ°è¾¾æœ€åä¸€é¡µæˆ–ä¸‹ä¸€é¡µæŒ‰é’®ä¸å¯ç”¨")
                return False

        except Exception as e:
            print(f"ç¿»é¡µæ—¶å‡ºé”™: ")
            return False

    def crawl(self, keywords, max_pages_per_keyword=30, need_login=False):
        """ä¸»çˆ¬å–æ–¹æ³•"""
        try:
            # åˆå§‹åŒ–é©±åŠ¨
            if not self.init_driver():
                return

            # åŠ è½½å·²ä¿å­˜çš„cookies
            cookies_loaded = self.load_cookies()

            # ç™»å½•é€»è¾‘è°ƒæ•´ï¼šå¦‚æœéœ€è¦ç™»å½•
            if need_login:
                if not cookies_loaded:
                    print("CookiesåŠ è½½å¤±è´¥ï¼Œå»ºè®®æ‰‹åŠ¨ç™»å½•å¹¶ä¿å­˜æ–°cookie")
                    if not self.login_with_qr():
                        print("ç™»å½•å¤±è´¥ï¼Œé€€å‡ºçˆ¬å–")
                        return
                else:
                    print("âœ… å·²åŠ è½½ cookiesï¼Œè·³è¿‡ç™»å½•")

            # å¼€å§‹çˆ¬å–
            all_products = []

            for keyword in keywords:
                print(f"\nå¼€å§‹çˆ¬å–å…³é”®è¯: {keyword}")
                products = self.search_products(keyword, max_pages_per_keyword)
                all_products.extend(products)

                # ä¿å­˜åˆ°æ•°æ®åº“
                if products:
                    self.save_to_database(products)

                # å…³é”®è¯é—´éš”
                time.sleep(2)

            print(f"\nçˆ¬å–å®Œæˆï¼æ€»å…±è·å– {len(all_products)} ä¸ªå•†å“")

        except Exception as e:
            print(f"çˆ¬å–è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        finally:
            if self.driver:
                self.driver.quit()
            if self.session:
                self.session.close()


def main():
    db_config = {
        'host': 'localhost',
        'port': 33309,
        'user': 'root',
        'password': '123456',
        'database': 'shopping_spark'
    }

    crawler = TmallCrawler(db_config, image_dir="shopping_crawl/tmall_images")

    # å¯åŠ¨çˆ¬è™«ï¼Œåªè°ƒç”¨ crawlï¼Œneed_login=True ä»¥ä¿è¯é¦–æ¬¡ç™»å½•æµç¨‹å¯è§¦å‘
    # crawler.crawl(keywords=["æ‰‹æœº", "ç©ºè°ƒ", "æ´—è¡£æœº"], max_pages_per_keyword=2, need_login=True)
    crawler.crawl(keywords=["ç å®"], max_pages_per_keyword=10, need_login=True)


if __name__ == "__main__":
    main()